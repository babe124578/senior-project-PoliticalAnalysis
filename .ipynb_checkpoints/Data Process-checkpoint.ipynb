{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if you are running from google colab\n",
    "# !pip install sklearn_crfsuite\n",
    "# !pip install emoji\n",
    "# !pip install https://github.com/PyThaiNLP/pythainlp/archive/dev.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pythainlp import word_tokenize\n",
    "from tqdm import tqdm_notebook\n",
    "from pythainlp.ulmfit import process_thai\n",
    "\n",
    "#viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyDrive and associated libraries.\n",
    "# This only needs to be done once per notebook.\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Download a file based on its file ID.\n",
    "#\n",
    "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
    "file_id = ' ' # FILE_ID in Google Drive\n",
    "downloaded = drive.CreateFile({'id': file_id})\n",
    "#print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n",
    "downloaded.GetContentFile('all.xlsx')\n",
    "import pandas as pd\n",
    "df  = pd.read_excel('all.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_url(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def remove_n(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    return text\n",
    "\n",
    "#https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: remove_punct(x))\n",
    "df['text'] = df['text'].apply(lambda x: remove_url(x))\n",
    "df['text'] = df['text'].apply(lambda x: remove_emoji(x))\n",
    "df['text'] = df['text'].apply(lambda x: remove_n(x))\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = df.rename(columns={'agreeOp':'col'})\n",
    "all_df = all_df[['text','col']]\n",
    "all_df.loc[all_df['col'] == 1, 'col'] = 0\n",
    "all_df['col'] *= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df, test_df = train_test_split(all_df, test_size=0.15, random_state=42)\n",
    "train_df, valid_df = train_test_split(all_df, test_size=0.15, random_state=1111)\n",
    "\n",
    "undersam = 4\n",
    "\n",
    "low = train_df[train_df.col==1]\n",
    "neu = train_df[train_df.col==0][::undersam]\n",
    "up = resample(low,\n",
    "                      replace=True, # sample with replacement\n",
    "                      n_samples=len(neu), # match number in majority class\n",
    "                      random_state=1111) # reproducible results\n",
    "upsampled = pd.concat([up, neu])\n",
    "train_df = upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)  \n",
    "\n",
    "y_train = train_df[\"col\"]\n",
    "y_valid = valid_df[\"col\"]\n",
    "y_test = test_df[\"col\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(tokenizer=process_thai, ngram_range=(1,2), min_df=20, sublinear_tf=True)\n",
    "tfidf_fit = tfidf.fit(all_df[\"text\"])\n",
    "text_train = tfidf_fit.transform(train_df[\"text\"])\n",
    "text_valid = tfidf_fit.transform(valid_df[\"text\"])\n",
    "text_test = tfidf_fit.transform(test_df[\"text\"])\n",
    "X_train = text_train.toarray()\n",
    "X_valid = text_valid.toarray()\n",
    "X_test = text_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "token = CountVectorizer(tokenizer=process_thai, ngram_range=(1,2), min_df=20)\n",
    "token_fit = token.fit(all_df[\"text\"])\n",
    "text_train = token_fit.transform(train_df[\"text\"])\n",
    "text_valid = token_fit.transform(valid_df[\"text\"])\n",
    "text_test = token_fit.transform(test_df[\"text\"])\n",
    "X_train = text_train.toarray()\n",
    "X_valid = text_valid.toarray()\n",
    "X_test = text_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE(random_state=1111)\n",
    "X_train,y_train = oversample.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# train model\n",
    "rfc = BernoulliNB().fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "rfc_pred = rfc.predict(X_valid)\n",
    "\n",
    "print(accuracy_score(y_valid, rfc_pred))\n",
    "print(precision_score(y_valid, rfc_pred))\n",
    "print(recall_score(y_valid, rfc_pred))\n",
    "print(f1_score(y_valid, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# train model\n",
    "rfc = DecisionTreeClassifier(random_state=1111).fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "rfc_pred = rfc.predict(X_valid)\n",
    "\n",
    "print(accuracy_score(y_valid, rfc_pred))\n",
    "print(precision_score(y_valid, rfc_pred))\n",
    "print(recall_score(y_valid, rfc_pred))\n",
    "print(f1_score(y_valid, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# train model\n",
    "rfc = RandomForestClassifier(random_state=1111).fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "rfc_pred = rfc.predict(X_valid)\n",
    "\n",
    "print(accuracy_score(y_valid, rfc_pred))\n",
    "print(precision_score(y_valid, rfc_pred))\n",
    "print(recall_score(y_valid, rfc_pred))\n",
    "print(f1_score(y_valid, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# train model\n",
    "rfc = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(), random_state=1111).fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "rfc_pred = rfc.predict(X_valid)\n",
    "\n",
    "print(accuracy_score(y_valid, rfc_pred))\n",
    "print(precision_score(y_valid, rfc_pred))\n",
    "print(recall_score(y_valid, rfc_pred))\n",
    "print(f1_score(y_valid, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# train model\n",
    "rfc = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", dual=False, multi_class=\"ovr\", random_state=1111).fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "rfc_pred = rfc.predict(X_valid)\n",
    "\n",
    "print(accuracy_score(y_valid, rfc_pred))\n",
    "print(precision_score(y_valid, rfc_pred))\n",
    "print(recall_score(y_valid, rfc_pred))\n",
    "print(f1_score(y_valid, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "filename = 'disAgreeOp.sav'\n",
    "joblib.dump(rfc, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
